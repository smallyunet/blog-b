---
title: 年终总结
tags: 年终
date: 2025-12-28 23:15:45
draft_date: 2025-12-28 20:40:19
---


### 债务

2025 年，是糟糕的一年。

最直观的数据是，我目前负债 7 万人民币左右。支出内容包括计算机科学课的学费、房租、失业期间的日常消费、生日礼物、相机、电吉他、电脑等。

贷款的来源是微粒贷、京东白条、信用卡等，不知道这些算不算人们常说的网贷。负债大都以分期的形式在还，最长的分 24 期，最短的还剩 3 期。所以虽然负债数字不小，但是短期的还债压力也不算大。

不久的将来，也就是再过几天（2026年了），我还会有一笔不小的支出，大概 5 万人民币左右，买黄金首饰。这样加起来，实际上总计负债会达到 12 万。

今年也是有收获的，只不过这些收获大多来自痛苦与挣扎，而不是循序渐进的那种努力和收获。之前在工作上遇到破事就不反复说了，有些事情，在一开始遇到的时候会觉得惊讶，但是后来逐渐明白，整个行业的情况都是这样，普遍存在。

### Side Project

#### 工作时长

出于基本的职业道德和职业素养，对于主业工作，我会主动保证基本的工作时长，算下来工作时长肯定是不低于平均水平的。

虽然远程工作多年了，但我仍然是出卖时间的工作方式。虽然鸡汤文学里都在告诉我们要出卖知识、技能、产品而不是时间，但是事实会告诉你很难做到，因为那些东西没有办法评估和量化，时间长度是最简单直接的衡量方式。

另外一个我没想通的逻辑是，中国地大物博、牛马众多，不缺的就是有能力的。所以你要说你想出卖技能，你有啥能力啊你就出卖，大多数人的能力都是平庸的。对于工作而言，把日常工作做好、能正常沟通、态度负责、及时响应、不出大的差错，承担好一个稳定的点，就已经及格了，甚至做的不错了。能做出出众工作表现的寥寥无几，尤其是把范围放大到整个行业里，整个世界上，人类历史上，而不局限于你自己的小圈子，你还想咋出众啊。很多自以为是的工作成果，其实都是在自己的圈子而言，如果打开门看看，没有人在乎。

#### 路线

1. 不运营博客，想写什么写什么，不要被流量绑架
2. 不打造人设，完全不想走那种网红（小丑）路线
3. 不要执着于观点和真理，观点总有枯竭的时候

代码仍然可以是好的资产。虽然文章也可以，但是文章免不了走上上述 3 条路线，所以不能走下去。

而代码，虽然生成式 AI 已经可以生成可靠的代码片段，但是现在的 AI 仍然缺少架构能力，面对复杂的场景根本无从下手。所以利用 AI 生成代码的能力，来做好一些脏活、节省他人的时间、开箱即用，也算是一种有价值的方向。AI 可以写出代码，但是需要经过成百上千次的调试、审查、功能验证、梳理，才算是一个项目。这就是项目本身的价值。

另一个话题是，在 AI 出现以前，传统公司的中层领导、CTO，其实本来就不写代码。AI 出现以后，他们仍然不写代码。所以事实上 AI 没有动摇他们的地位。假如你担心自己写代码的能力被 AI 取代，那么问题就在于其实是因为你没有能力胜任更高级别的架构角色，不能怪 AI。

#### 项目

最近一个月，我花了不少时间创建一些 Side Project。既然 AI 的趋势势不可挡，那么就干脆尽可能发挥 AI 的能力试试，让自己的角色变为 AI 指挥家，看看 AI 的高效率能做出多少东西，能不能产生有意思的东西。

我给自己创建了一个 [Dashboard](https://spd.smallyu.net/) 来管理这些新的 Side Project（旧的不维护了），主要是给自己看，用来追踪哪些项目有段时间没更新了，就动手跟进哪些项目。

现在 Dashboard 中有 17 个项目。数量有点多，在这么多项目之间做上下文切换是很难的，我知道是一种负担，而且会花费很多时间。给自己工作也算工作，所以实际上平时空闲时间有点少。一方面想做点东西试试，另一方面又确实做不过来，砍掉一些项目又不愿意。这些项目其实都有意思，只是时间不够用。

Dashboard 中给项目分了 3 类，第一类是基建类，包括之前的 EchoEVM 和 EthBFT 也都放进去了，以及新增的一些，比如用 Go 语言实现一个 TSS 库、用 Rust 语言实现一个零拷贝高性能的 EVM 字节码解码库、能处理区块重组的 EVM 事件索引器等。

第二类是组件库、依赖包、SDK 一类，比如比特币的 PSBT 解码库、Solana 的交易解析和可视化库、蜜罐合约的示例、Safe Wallet 的 Python 版本 SDK 等。

第三类是软件和工具类，能直接用的那种，这个分类的项目可以具体介绍下：

- [konachan-downloader](https://github.com/smallyunet/konachan-downloader)

一个基于 Python 的命令行工具，一键多线程下载 Konachan 网站的全部二次元壁纸，我用 6 个小时下载了 2 万多张图片，占用磁盘空间 150 GB 左右，下载了 Konachan 图片总量的大概 1/6。要不是硬盘空间和流量不够用，肯定全部下载下来……

- [finder-sight](https://github.com/smallyunet/finder-sight)

一个基于 Python 图形库的软件，已经打包成了 MacOS App，功能是在本地以图搜图，针对某一些目录的图片建立索引，然后用图片的一部分就可以搜索匹配到在本地文件的哪里。

当下载了大量壁纸并且随机显示到桌面之后，有时候会发现桌面上看到的壁纸并不好看，想删掉，但是又不知道怎么找具体是本地文件夹里的哪一个。所以需要一个本地以图搜图的软件。

- [vscode-antigravity-hud](https://github.com/smallyunet/vscode-antigravity-hud)

一个用于 Google Antigravity 编辑器的插件。我目前日常使用 Antigravity，但是谷歌默认不显示模型的使用量和剩余使用量，所以就可以用这个插件来看具体的消耗情况，以及下一次重置用量的时间。这个插件不算有特点，因为插件库有很多其他同类型的、相同功能的插件，只是我自己想搞一个比较简洁一点的用。

- [chatgpt-visualizer](https://github.com/smallyunet/chatgpt-visualizer)

ChatGPT 可以一键导出全部的聊天数据，但是他自己附带的网页非常简陋，而且如果数据量大，比如我的数据有 1 GB，网页加载会直接把 chrome 浏览器卡死。所以想开发一个能加载大量数据、现代化聊天 UI 的本地工具。而且本地数据搜索起来是非常快的，如果用 ChatGPT 的平台，数据请求都得等待他们的网络响应，会很慢。

再一个原因就是我现在不用 ChatGPT 了，用 Gemini，所以需要把 ChatGPT 的数据归档。Google 发明了 Transformer、原生多模态、用 TPU 训练大模型、一年的营收大于 OpenAI 的总估值等，这些关键词都在暗示 Gemini 比 ChatGPT 更有潜力。

#### 小结

补充一点，关于做 Side Project 的想法，其实一开始来自于 Péter Szilágyi 的一条 [X 帖子](https://x.com/peter_szilagyi/status/1999121102140756037)。Péter Szilágyi 以前是以太坊客户端 Geth 的 Leader，看起来今年离开了以太坊，开始建立一个叫 Dark Bio 的项目。当时看到 Péter Szilágyi 这样的人物都还在关注代码库这些东西，还发布了 crates 包，虽然下载量不高。受到 Péter Szilágyi 的启发，我才动了做一些开源组件库的念头。

大概就这些。我很清楚我做的这些 Side Project 属于 “虚假的勤奋”、“用战术上的勤奋掩盖战略上的懒惰” 什么的。但暂时还想做下去。

### 学习

计算机科学课程中的内容，比原本设想的更需要反复理解，所以来年还是要继续学习好这些理论基础。


